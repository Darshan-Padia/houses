# -*- coding: utf-8 -*-
"""houses_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12kcFTPLnnyhHbxbEozoBTyTMpy8d1vKh
"""

# importing the libraries
import matplotlib.pyplot as plt
import numpy as np
import cv2
import os
import PIL
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential

dataset_dir = 'backend/classes'

import pathlib
data_dir = pathlib.Path(dataset_dir)

# dataset has jpg , jpeg and JPG format
length = len(list(data_dir.glob('*/*.jpeg'))) + len(list(data_dir.glob('*/*.jpg'))) + len(list(data_dir.glob('*/*.JPG')))
print(f'len {length}')


houses_dict = {
    'type_a' : list(data_dir.glob('Type_A/*')),
    'type_b' : list(data_dir.glob('Type_B/*')),
    'type_c' : list(data_dir.glob('Type_C/*'))

}

houses_labels_dict = {
    'type_a' : 0,
    'type_b' : 1,
    'type_c' : 2

}


# all images dimension are not same hence resize
X,y =[],[]
for house_type , images in houses_dict.items():
  for image in images:
    img = cv2.imread(str(image))
    resized_img = cv2.resize(img,(180,180))
    X.append(resized_img)
    y.append(houses_labels_dict[house_type])

X = np.array(X)
y = np.array(y)

# from sklearn.model_selection import train_test_split
# X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 0)



import os
import numpy as np
from pathlib import Path
import cv2

# Define the dataset directory
# dataset_dir = '/content/drive/MyDrive/houses/houses_project'

# Custom train-test split
X_train, X_test, y_train, y_test = [], [], [], []
test_image_paths = []

# Loop through each folder
for folder_name in os.listdir(dataset_dir):
    folder_path = os.path.join(dataset_dir, folder_name)

    # Ensure that it's a directory
    if os.path.isdir(folder_path):
        image_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) ]  # Assuming images have jpg or png extension
        num_images = len(image_paths)
        num_test_images = int(0.27 * num_images)  # Assuming 20% of images for testing

        # Splitting the image paths into train and test
        test_paths = image_paths[:num_test_images]
        test_image_paths.extend(test_paths)
        train_paths = image_paths[num_test_images:]

        # Load and resize test images
        for img_path in test_paths:
            img = cv2.imread(img_path)
            resized_img = cv2.resize(img, (180, 180))
            X_test.append(resized_img)
            y_test.append(houses_labels_dict[folder_name.lower()])  # Assuming folder name is the label

        # Load and resize train images
        for img_path in train_paths:
            img = cv2.imread(img_path)
            resized_img = cv2.resize(img, (180, 180))
            X_train.append(resized_img)
            y_train.append(houses_labels_dict[folder_name.lower()])  # Assuming folder name is the label

# Convert lists to numpy arrays
X_train = np.array(X_train)
X_test = np.array(X_test)
y_train = np.array(y_train)
y_test = np.array(y_test)

# Checking the shape of the arrays
print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)


# You can now use X_test and y_test for testing





# scalling the pixels
X_train_scaled = X_train / 255.0
X_test_scaled = X_test / 255.0

num_classes = 3

# model = Sequential([
#     layers.Conv2D(16,3,padding='same',activation = 'relu'),
#     layers.LeakyReLU(0.1),
#     layers.MaxPooling2D(),

#     layers.Conv2D(32,3,padding='same',activation = 'relu'),
#     layers.LeakyReLU(0.1),
#     layers.MaxPooling2D(),

#     layers.Conv2D(64,3,padding='same',activation = 'relu'),
#     layers.LeakyReLU(0.1),

#     layers.MaxPooling2D(),

#     # before starting dense we hagve to flatten
#     layers.Flatten(),
#     layers.Dense(128,activation = 'softmax'),
#     layers.Dense(num_classes)

# ])
model = Sequential([
    layers.Conv2D(16, 3, padding='same', activation='relu'),
    layers.MaxPooling2D(),

    layers.Conv2D(32, 3, padding='same', activation='relu'),
    layers.MaxPooling2D(),

    layers.Conv2D(64, 3, padding='same', activation='relu'),
    layers.MaxPooling2D(),

    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(num_classes, activation='softmax')
])

model.compile(optimizer = 'adam',
              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),
              metrics = ['accuracy'])

model.fit(X_train_scaled,y_train,epochs = 10)
model.save('model_save/custom_train_test_plain2')

print(model.evaluate(X_test_scaled,y_test))
print()
print()
print()



from tensorflow.keras.models import load_model
import numpy as np
import cv2

# Load the trained model
model = load_model('model_save/custom_train_test_plain2')  # Provide the path to your saved model

# Define a function to preprocess images
def preprocess_image(image):
    # Resize the image to match the input size of the model
    image = cv2.resize(image, (180, 180))
    # Convert image to array and normalize
    image = image.astype('float32') / 255.0
    # Add batch dimension
    image = np.expand_dims(image, axis=0)
    return image

# Define a function to make predictions on a single image
def predict_single_image(image):
    # Preprocess the image
    image = preprocess_image(image)
    # Make prediction
    prediction = model.predict(image)
    # Get the predicted class label
    predicted_class = np.argmax(prediction)
    return predicted_class

# Path to the directory containing images
# folder_path = '/content/drive/MyDrive/houses/houses_project/Type_A'

# Iterate over each image in the folder
# for filename in os.listdir(folder_path):
#     if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png') or filename.endswith('.JPG') or filename.endswith('.JPEG'):
#         # Load the image
#         image_path = os.path.join(folder_path, filename)
#         image = cv2.imread(image_path)

#         # Make prediction on the image
#         predicted_class = predict_single_image(image)

#         # Display the predicted class label
#         print(f"Image: {filename}, Predicted Class: {predicted_class}")

for item in test_image_paths:
  #  Load the image
    # image_path = os.path.join(folder_path, filename)
    image = cv2.imread(item)

    # Make prediction on the image
    predicted_class = predict_single_image(image)

    # Display the predicted class label
    print(f"Image: {item}, Predicted Class: {predicted_class}")
